const flashcards = [
  { 
    term: "Supervised Learning", 
    definition: "A type of machine learning where the model is trained on labeled data.",
    difficulty: "Easy"
  },
  { 
    term: "Overfitting", 
    definition: "A model that learns the training data too well, including noise, and performs poorly on new data.",
    difficulty: "Medium"
  },
  { 
    term: "Normalization", 
    definition: "A technique to scale data to a standard range, often [0, 1], to improve model training.",
    difficulty: "Easy"
  },
  { 
    term: "Unsupervised Learning", 
    definition: "A type of machine learning where the model is trained on unlabeled data and tries to find hidden patterns or structures.",
    difficulty: "Medium"
  },
  { 
    term: "Cross-Validation", 
    definition: "A technique used to assess how the results of a statistical analysis will generalize to an independent data set, often by splitting the data into multiple subsets.",
    difficulty: "Medium"
  },
  { 
    term: "Feature Engineering", 
    definition: "The process of using domain knowledge to create new features or modify existing features to improve model performance.",
    difficulty: "Medium"
  },
  { 
    term: "Gradient Descent", 
    definition: "An optimization algorithm used to minimize the cost function by iteratively adjusting model parameters.",
    difficulty: "Medium"
  },
  { 
    term: "Support Vector Machine (SVM)", 
    definition: "A supervised learning algorithm that finds the hyperplane that best separates different classes in the feature space.",
    difficulty: "Hard"
  },
  { 
    term: "Neural Network", 
    definition: "A computational model inspired by the human brain, consisting of layers of interconnected nodes or neurons, used for tasks such as classification and regression.",
    difficulty: "Hard"
  },
  { 
    term: "Decision Tree", 
    definition: "A model that uses a tree-like graph of decisions and their possible consequences to make predictions or decisions based on input features.",
    difficulty: "Medium"
  },
  { 
    term: "Principal Component Analysis (PCA)", 
    definition: "A dimensionality reduction technique that transforms data into a new coordinate system where the greatest variances lie on the first coordinates.",
    difficulty: "Medium"
  },
  { 
    term: "K-Nearest Neighbors (KNN)", 
    definition: "A simple, instance-based learning algorithm that classifies data points based on the majority label of their k-nearest neighbors in the feature space.",
    difficulty: "Medium"
  },
  { 
    term: "Random Forest", 
    definition: "An ensemble learning method that combines multiple decision trees to improve classification accuracy and control overfitting.",
    difficulty: "Hard"
  },
  { 
    term: "Clustering", 
    definition: "An unsupervised learning technique used to group similar data points together based on their features, without predefined labels.",
    difficulty: "Medium"
  },
  { 
    term: "Hyperparameter", 
    definition: "A parameter whose value is set before the learning process begins and is not learned from the data, such as the learning rate or number of layers in a neural network.",
    difficulty: "Medium"
  },
  { 
    term: "Deep Learning", 
    definition: "A subset of machine learning that uses neural networks with many layers (deep networks) to model complex patterns in large datasets.",
    difficulty: "Hard"
  },
  { 
    term: "Regularization", 
    definition: "A technique used to prevent overfitting by adding a penalty to the loss function based on the magnitude of model parameters.",
    difficulty: "Medium"
  },
  { 
    term: "Confusion Matrix", 
    definition: "A table used to evaluate the performance of a classification model by comparing the predicted labels with the true labels.",
    difficulty: "Medium"
  },
  { 
    term: "ROC Curve", 
    definition: "A graphical representation of a classifier's performance, showing the trade-off between true positive rate and false positive rate at various threshold settings.",
    difficulty: "Medium"
  },
  { 
    term: "F1 Score", 
    definition: "A measure of a model's accuracy that considers both precision and recall, calculated as the harmonic mean of the two.",
    difficulty: "Medium"
  },
  { 
    term: "Bagging", 
    definition: "An ensemble technique that improves model performance by training multiple instances of the model on different subsets of the data and averaging their predictions.",
    difficulty: "Hard"
  },
  { 
    term: "Boosting", 
    definition: "An ensemble technique that combines the predictions of several weak models to create a strong model by focusing on correcting errors of previous models.",
    difficulty: "Hard"
  },
  { 
    term: "Exploratory Data Analysis (EDA)", 
    definition: "The process of analyzing data sets to summarize their main characteristics, often with visual methods, before applying more formal modeling techniques.",
    difficulty: "Easy"
  },
  { 
    term: "Latent Variable", 
    definition: "An unobserved variable that influences observed variables in a model, often used in techniques like factor analysis and hidden Markov models.",
    difficulty: "Medium"
  },
];

export default flashcards;
